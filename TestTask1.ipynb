{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import data\n",
    "import model\n",
    "\n",
    "from utils import batchify, get_batch, repackage_hidden\n",
    "#import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(data_source, batch_size=10):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    if args.model == 'QRNN': model.reset()\n",
    "    total_loss = 0\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i in range(0, data_source.size(0) - 1, args.bptt):\n",
    "        #print('eval:',i)\n",
    "        #print('before get_batch,  max_memory_reserved():',torch.cuda.max_memory_reserved()/1024/1024)\n",
    "        data, targets = get_batch(data_source, i, args, evaluation=True)\n",
    "        #print('after get_batch,  max_memory_reserved():',torch.cuda.max_memory_reserved()/1024/1024)\n",
    "        output, hidden = model(data, hidden)\n",
    "        total_loss += len(data) * criterion(model.decoder.weight, model.decoder.bias, output, targets).data\n",
    "        hidden = repackage_hidden(hidden)\n",
    "    return total_loss.item() / len(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(fn):\n",
    "    global model, criterion, optimizer\n",
    "    #if args.philly:\n",
    "        #fn = os.path.join(os.environ['PT_OUTPUT_DIR'], fn)\n",
    "    #fn = '1591009087197056.pt'\n",
    "    with open(fn, 'rb') as f:\n",
    "        model, criterion, optimizer = torch.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing dataset...\n"
     ]
    }
   ],
   "source": [
    "#print('Loading cached dataset...')\n",
    "#corpus = torch.load('corpus.148650ff682fa3f76e78c18d7d6d5bd6.data')\n",
    "\n",
    "print('Producing dataset...')\n",
    "corpus = data.Corpus('data/penn2/')\n",
    "#torch.save(corpus, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1\n",
    "#args = {'cuda':True}\n",
    "class arg1:\n",
    "    cuda = True\n",
    "    model  = 'LSTM'\n",
    "    bptt = 70\n",
    "args = arg1()\n",
    "test_data = batchify(corpus.test, test_batch_size, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([213, 1])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  7.57 | test ppl  1946.00 | test bpc   10.926\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model.\n",
    "model_load('1591009087197056.pt')\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data, test_batch_size)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | test bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
